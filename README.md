# Protein Representation Learning from Single-cell Microscopy Data

<!--![Build status](https://img.shields.io/github/workflow/status/bowang-lab/BIONIC/Python%20package)
![Version](https://img.shields.io/github/v/release/bowang-lab/BIONIC)
![Top language](https://img.shields.io/github/languages/top/bowang-lab/BIONIC)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.6762584.svg)](https://doi.org/10.5281/zenodo.6762584)
-->
![License](https://img.shields.io/github/license/arazd/protein_representation_learning)

**Check out our [paper (ICLR 2022, MLDD workshop)](https://arxiv.org/abs/2205.11676)!**

Cite:
```
@article{razdaibiedina2022learning,
  title={Learning multi-scale functional representations of proteins from single-cell microscopy data},
  author={Razdaibiedina, Anastasia and Brechalov, Alexander},
  journal={arXiv preprint arXiv:2205.11676},
  year={2022}
}
```

## About
Despite major developments in molecular representation learning, **extracting functional information from biological images** remains a non-trivial
computational task. In this work, we revisit deep learning models used for *classifying major subcellular localizations*, and evaluate
*representations extracted from their final layers*. We show that **simple convolutional networks trained on localization classification can learn protein representations that encapsulate diverse functional information**, and significantly outperform currently used autoencoder-based models. 

## Methods & Results

## How to run
